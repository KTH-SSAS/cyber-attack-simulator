{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fda8002-e229-4373-8431-b4458568218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from ray import init, rllib, tune, shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b148c8c-c3e1-4a6e-9f23-d9974348334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_simulator.agents import DEFENDERS\n",
    "from attack_simulator.env import AttackSimulationEnv\n",
    "from attack_simulator.graph import AttackGraph, SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d59b78-7bc4-48c5-9d53-a0ed7a73f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPolicy(rllib.policy.Policy):\n",
    "    def __init__(self, observation_space, action_space, config):\n",
    "        super().__init__(observation_space, action_space, config)\n",
    "        agent_config = dict(\n",
    "            input_dim=observation_space.shape[0],\n",
    "            num_actions=action_space.n,\n",
    "            random_seed=config[\"seed\"],\n",
    "            attack_graph=config[\"env_config\"][\"attack_graph\"],\n",
    "        )\n",
    "        self._agent = DEFENDERS[config[\"agent_type\"]](agent_config)\n",
    "\n",
    "    def compute_actions(self, observations, *args, **kwargs):\n",
    "        # FIXME: use a `numpy` array as a temporary workaround for\n",
    "        #        https://github.com/ray-project/ray/issues/10100\n",
    "        return np.array([self._agent.act(obs) for obs in observations]), [], {}\n",
    "\n",
    "    def get_weights(self):\n",
    "        return {}\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        pass\n",
    "\n",
    "\n",
    "def template_agent(agent_type):\n",
    "    default_config = rllib.agents.trainer.with_common_config(dict(agent_type=agent_type))\n",
    "    return rllib.agents.trainer_template.build_trainer(\n",
    "        name=agent_type,\n",
    "        default_policy=AgentPolicy,\n",
    "        default_config=default_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c41ecb4-e26b-46ad-a2d6-bd09cf3b7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class AttackSimAlphaZeroEnv(AttackSimulationEnv):\n",
    "    def set_state(self, state):\n",
    "        (\n",
    "            self.simulation_time,\n",
    "            self.ttc_remaining,\n",
    "            self.attack_surface,\n",
    "            self.attack_state,\n",
    "            self.service_state,\n",
    "            self._observation,\n",
    "        ) = deepcopy(state)\n",
    "\n",
    "    def get_state(self):\n",
    "        state = (\n",
    "            self.simulation_time,\n",
    "            self.ttc_remaining,\n",
    "            self.attack_surface,\n",
    "            self.attack_state,\n",
    "            self.service_state,\n",
    "            self._observation,\n",
    "        )\n",
    "        return deepcopy(state)\n",
    "    \n",
    "\n",
    "class AlphaZeroWrapper(gym.Env):\n",
    "    def __init__(self, config):\n",
    "        self.env = config[\"env_class\"](config)\n",
    "        self.action_space = self.env.action_space\n",
    "        assert isinstance(\n",
    "            self.action_space, gym.spaces.Discrete\n",
    "        ), \"AlphaZero requires a Discrete action space\"\n",
    "        shape = (self.action_space.n,)\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            dict(obs=self.env.observation_space, action_mask=gym.spaces.Box(0, 1, shape))\n",
    "        )\n",
    "        self.reward = 0\n",
    "        self.mask = np.full(shape, 1, dtype=\"int8\")\n",
    "\n",
    "    def reset(self):\n",
    "        self.reward = 0\n",
    "        observation = self.env.reset()\n",
    "        return dict(obs=observation, action_mask=self.mask)\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, done, info = self.env.step(action)\n",
    "        self.reward += reward\n",
    "        reward = self.reward if done else 0\n",
    "        return dict(obs=observation, action_mask=self.mask), reward, done, info\n",
    "\n",
    "    def set_state(self, state):\n",
    "        env_state, self.reward = state\n",
    "        self.env.set_state(env_state)\n",
    "        return dict(obs=self.env.observation, action_mask=self.mask)\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.env.get_state(), self.reward\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "\n",
    "    def render(self, mode=None):\n",
    "        self.env.render(mode)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.env.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c397d725-6f0e-43c4-9fc7-5f13e41e11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'contrib/AlphaZero' does NOT appear to work without its custom dense model\n",
    "from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "\n",
    "rllib.models.ModelCatalog.register_custom_model(\"alpha_zero_dense_model\", DenseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7211eb85-4419-46a1-9848-876e074e8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work around: https://github.com/ray-project/ray/issues/17618\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "class keep_ipython_sane:\n",
    "    def __enter__(self):\n",
    "        self.instance = InteractiveShell.instance()\n",
    "        \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        # feel free to improve with error handling, etc.\n",
    "        InteractiveShell._instance = self.instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f262a77-9f87-436a-8208-a3f1bad01b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"/var/run/secrets/kubernetes.io\"):  # inside k8s pod\n",
    "    args = dict(address=\"auto\")\n",
    "else:\n",
    "    # listen on all interfaces inside a container for port-forwarding to work\n",
    "    dashboard_host = \"0.0.0.0\" if os.path.exists(\"/.dockerenv\") else \"127.0.0.1\"\n",
    "    args = dict(num_cpus=4, dashboard_host=dashboard_host)\n",
    "\n",
    "# ALTERNATIVE: use the \"Ray client\" to connect to a remote cluster\n",
    "# Unfortunately, JupyterNotebookReporter displays an object reference\n",
    "# <IPython.core.display.HTML object> instead of content...\n",
    "# --- --- ---\n",
    "#\n",
    "# from ray.util.client import worker\n",
    "#\n",
    "# worker.INITIAL_TIMEOUT_SEC = worker.MAX_TIMEOUT_SEC = 1\n",
    "#\n",
    "# ray_client_server = 'host.docker.internal' if os.path.exists(\"/.dockerenv\") else '127.0.0.1'\n",
    "# try:\n",
    "#     init(address=f'ray://{ray_client_server}:10001')\n",
    "# except Connection Error:\n",
    "#     pass  # TODO: try something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07955c84-9b17-4f58-a967-346cf9de18c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 18:29:29,242\tINFO services.py:1263 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.17.0.3:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.3',\n",
       " 'raylet_ip_address': '172.17.0.3',\n",
       " 'redis_address': '172.17.0.3:37513',\n",
       " 'object_store_address': '/tmp/ray/session_2021-09-22_18-29-27_638029_58161/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-09-22_18-29-27_638029_58161/sockets/raylet',\n",
       " 'webui_url': '172.17.0.3:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-09-22_18-29-27_638029_58161',\n",
       " 'metrics_export_port': 62432,\n",
       " 'node_id': '859f7328f511641f697d460824454afa9fc624a706e716418f2ae7fa'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a242dbab-5252-45fd-998f-7d3fdbcd7ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackGraph(en2720.yaml[tiny], 2 services, 7 attack steps)\n",
      "AttackGraph(en2720.yaml[small], 5 services, 27 attack steps)\n",
      "AttackGraph(en2720.yaml[medium-small], 9 services, 44 attack steps)\n",
      "AttackGraph(en2720.yaml[medium], 13 services, 56 attack steps)\n",
      "AttackGraph(en2720.yaml[large], 16 services, 62 attack steps)\n",
      "AttackGraph(en2720.yaml[extra-large], 16 services, 65 attack steps)\n",
      "AttackGraph(en2720.yaml[full], 18 services, 78 attack steps)\n"
     ]
    }
   ],
   "source": [
    "# FIXME: temporarily omit \"contrib/AlphaZero\" due to https://github.com/ray-project/ray/issues/13177\n",
    "# agent_types = [\"contrib/AlphaZero\", \"R2D2\", \"rule-based\", \"random\"]\n",
    "agent_types = [\"R2D2\", \"rule-based\", \"random\"]\n",
    "graphs = [AttackGraph(dict(graph_size=size)) for size in SIZES]\n",
    "seeds = [0, 1, 2, 3, 6, 7, 11, 28, 42, 1337]\n",
    "iterations = 10\n",
    "rollouts = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82288776-0055-4032-8923-8ce0ba9e0564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 20:35:39,894\tWARNING deprecation.py:38 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS::model DenseModel(\n",
      "  (shared_layers): Sequential(\n",
      "    (0): Linear(in_features=96, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (actor_layers): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=19, bias=True)\n",
      "  )\n",
      "  (critic_layers): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603ac7959d1a4f71ba136162c95c637f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1341.46875 20.3125\n",
      "{'total_loss': 1.9323424, 'policy_loss': 2.9082537, 'value_loss': 0.95643103}\n",
      "MCTS::compute_action 7 -1.0 True 1.0 -1.0\n",
      "MCTS::compute_action True -1.0 31.0 -31.0 30\n",
      "MCTS::compute_action <ray.rllib.contrib.alpha_zero.core.mcts.Node object at 0xfffeb1944ac0>\n",
      "MCTS::compute_action {'env': <ray.rllib.contrib.alpha_zero.core.ranked_rewards.get_r2_env_wrapper.<locals>.RankedRewardsEnvWrapper object at 0xffff301cbcd0>, 'action': 7, 'is_expanded': False, 'parent': <ray.rllib.contrib.alpha_zero.core.mcts.Node object at 0xffff301d8910>, 'children': {}, 'action_space_size': 19, 'child_total_value': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32), 'child_priors': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32), 'child_number_visits': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32), 'valid_actions': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True]), 'reward': -1.0, 'done': True, 'state': {'env_state': ((94, array([  1,  16,   1,   1,  19,  10,   1,   1,   1,   1,   1,   3,   1,\n",
      "         1,   1,   1,   1,   1,   2,   4,   1,   1,   1,   1,   0,  38,\n",
      "        12,   0,   0,   4,  10, 518,   8,   1,   1,   1,   6,  12,   1,\n",
      "         2,   1,   1,  22,   0,   2,   1,   0,   0,   0,   0,   1,   0,\n",
      "         5,   4,   3,   1,  16,   0,   0,   6,  48, 145,  56,   1,   1,\n",
      "         1,   1,   2,   1,   1,  21,  26,   1,  18,   1,   1,   2,  25]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0])), -304), 'buffer_state': array([ 1.3400e+02,  1.5700e+02,  2.2600e+02,  2.2100e+02,  2.1300e+02,\n",
      "        1.3000e+02,  1.5000e+02, -1.0088e+04,  1.5400e+02,  1.3000e+02,\n",
      "        1.4300e+02,  1.3000e+02, -3.6350e+03,  1.7300e+02,  2.1200e+02,\n",
      "        2.9900e+02, -2.4193e+04,  8.0000e+01,  1.0900e+02,  6.5000e+01,\n",
      "        1.7600e+02,  1.5100e+02,  1.7900e+02,  2.1800e+02, -1.8782e+04,\n",
      "        3.4000e+01,  1.4000e+02,  1.4500e+02,  1.8500e+02,  1.1400e+02,\n",
      "       -1.0636e+04, -8.7100e+03,  1.8400e+02,  1.0900e+02, -5.0180e+03,\n",
      "        2.4500e+02,  1.9100e+02,  1.5600e+02,  2.7900e+02,  1.4600e+02,\n",
      "        1.2200e+02,  2.3600e+02,  1.3400e+02,  1.5400e+02, -1.3969e+04,\n",
      "        5.9000e+01,  1.8300e+02,  3.2900e+02,  2.5200e+02,  2.0700e+02,\n",
      "        1.0900e+02, -7.2580e+03,  2.6100e+02, -4.4448e+04,  1.3000e+02,\n",
      "        8.0000e+01,  1.7800e+02, -3.5415e+04,  9.2000e+01,  2.1000e+02,\n",
      "        1.5100e+02,  9.4000e+01,  1.7800e+02, -1.0010e+03,  1.1800e+02,\n",
      "        2.8000e+02,  1.4800e+02,  2.2600e+02, -4.0800e+02,  2.1600e+02,\n",
      "        9.7000e+01,  8.1000e+01,  1.8100e+02, -8.3700e+03,  1.7600e+02,\n",
      "        1.5100e+02,  2.7200e+02,  1.7600e+02, -2.4050e+03,  2.4800e+02,\n",
      "        1.1000e+02,  1.4300e+02,  1.9400e+02,  2.2100e+02,  2.2900e+02,\n",
      "        1.1900e+02,  1.6500e+02,  9.3000e+01,  1.9600e+02,  2.9900e+02,\n",
      "        1.8100e+02,  1.3800e+02,  1.1500e+02,  1.2100e+02,  1.6200e+02,\n",
      "       -1.3520e+03,  1.0500e+02,  1.7400e+02,  2.1200e+02, -4.2480e+03,\n",
      "        1.9400e+02,  1.9400e+02,  3.5700e+02, -8.9290e+03, -1.2087e+04,\n",
      "       -2.5450e+03,  2.4400e+02, -1.3343e+04,  6.8000e+01,  1.0400e+02,\n",
      "        1.8200e+02,  1.9600e+02,  1.7400e+02,  1.3300e+02, -9.5980e+03,\n",
      "        1.9500e+02,  1.9600e+02,  1.5400e+02,  2.0100e+02,  1.6700e+02,\n",
      "        2.2600e+02,  1.5900e+02,  1.6500e+02, -1.3900e+03,  2.2200e+02,\n",
      "        1.9800e+02,  1.6100e+02,  2.3900e+02,  1.5400e+02,  2.0100e+02,\n",
      "        1.8700e+02,  2.9400e+02,  1.7500e+02, -3.5900e+02,  2.0700e+02,\n",
      "       -4.9380e+03, -1.9420e+03,  2.0000e+02,  1.9700e+02,  1.3800e+02,\n",
      "        2.0000e+02,  1.2300e+02,  2.7800e+02,  2.5900e+02,  1.8400e+02])}, 'obs': {'obs': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0]), 'action_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "      dtype=int8)}, 'mcts': <ray.rllib.contrib.alpha_zero.core.mcts.MCTS object at 0xffff3007ff40>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:153: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tree_policy = tree_policy / np.max(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58161/187928499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default_policy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learner_stats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_reward_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_len_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow logs messages to propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_WORKER_FAILURE_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRayError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ignore_worker_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# No evaluation necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevaluate_this_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;31m# We have to evaluate in this training iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_flatten\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T[0]]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36madd_wait_hooks\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    826\u001b[0m                             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_fetch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                         \u001b[0mnew_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                         \u001b[0mnew_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/execution/rollout_ops.py\u001b[0m in \u001b[0;36msampler\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         return (LocalIterator(sampler, SharedMetrics())\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                 self.rollout_fragment_length))\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0msteps_so_far\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_steps_by\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"env_steps\"\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSampleBatchType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extra_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSampleBatchType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_provider\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRolloutMetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36m_env_runner\u001b[0;34m(worker, base_env, extra_batch_callback, rollout_fragment_length, horizon, clip_rewards, normalize_actions, clip_actions, multiple_episodes_in_batch, callbacks, perf_stats, soft_horizon, no_done_at_end, observation_fn, sample_collector, render)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;31m# types: Dict[PolicyID, Tuple[TensorStructType, StateBatch, dict]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         eval_results = _do_policy_eval(\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0mto_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mpolicies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\u001b[0m in \u001b[0;36m_do_policy_eval\u001b[0;34m(to_eval, policies, policy_mapping_fn, sample_collector, active_episodes)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inference_input_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicy_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             policy.compute_actions_from_input_dict(\n\u001b[0m\u001b[1;32m   1029\u001b[0m                 \u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_timestep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/contrib/alpha_zero/core/alpha_zero_policy.py\u001b[0m in \u001b[0;36mcompute_actions_from_input_dict\u001b[0;34m(self, input_dict, explore, timestep, episodes, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# run monte carlo simulations to compute the actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;31m# and record the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 mcts_policy, action, tree_node = self.mcts.compute_action(\n\u001b[0m\u001b[1;32m     91\u001b[0m                     tree_node)\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# record action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/attack-simulator-_8mgyPy8-py3.8/lib/python3.8/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py\u001b[0m in \u001b[0;36mcompute_action\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# otherwise sample an action according to tree policy probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             action = np.random.choice(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 np.arange(node.action_space_size), p=tree_policy)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "config = dict(\n",
    "    framework=\"torch\",\n",
    "    model=dict(custom_model=\"alpha_zero_dense_model\"),\n",
    "    env=AlphaZeroWrapper,\n",
    "    env_config=dict(attack_graph=graphs[-1], env_class=AttackSimAlphaZeroEnv),\n",
    "    seed=seeds[-1],\n",
    "    num_workers=0,\n",
    "    batch_mode=\"complete_episodes\",\n",
    "    rollout_fragment_length=32,\n",
    "    train_batch_size=640,\n",
    "    buffer_size=512,\n",
    "    mcts_config=dict(add_dirichlet_noise=False),\n",
    "    # ranked_rewards=dict(enable=False),\n",
    ")\n",
    "\n",
    "agent_type = \"contrib/AlphaZero\"\n",
    "\n",
    "with keep_ipython_sane():\n",
    "    agent = rllib.agents.registry.get_trainer_class(agent_type)(config=config)\n",
    "\n",
    "total_loss = 0\n",
    "for _ in tqdm(range(iterations)):\n",
    "    results = agent.train()\n",
    "    stats = results['info']['learner']['default_policy']['learner_stats']\n",
    "    print(results['episode_reward_mean'], results['episode_len_mean'])\n",
    "    print(stats)\n",
    "    delta = stats['total_loss'] - total_loss\n",
    "    if abs(delta) < 1e-6:\n",
    "        break\n",
    "    total_loss = stats['total_loss']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396df855-f71a-4b41-adf5-ac7922755c87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65537/2893324054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default_policy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learner_stats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results['info']['learner']['default_policy']['learner_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb8a4c-6aa2-4e41-b86c-e622f9b2c27c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.tune.utils.trainable import TrainableUtil\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "rename = dict(\n",
    "    agent_type=\"Agent\",\n",
    "    graph_size=\"Graph size\",\n",
    "    episode_length=\"Episode lengths\",\n",
    "    episode_reward=\"Returns\",\n",
    ")\n",
    "\n",
    "# FIXME: temporarily omit \"contrib/AlphaZero\" due to https://github.com/ray-project/ray/issues/13177\n",
    "# agent_types = [\"contrib/AlphaZero\", \"R2D2\", \"rule-based\", \"random\"]\n",
    "agent_types = [\"R2D2\", \"rule-based\", \"random\"]\n",
    "graphs = [AttackGraph(dict(graph_size=size)) for size in SIZES]\n",
    "seeds = [0, 1, 2, 3, 6, 7, 11, 28, 42, 1337]\n",
    "iterations = 10\n",
    "rollouts = 10\n",
    "\n",
    "eval_config = dict(\n",
    "    evaluation_interval=1,\n",
    "    evaluation_num_workers=1,\n",
    "    evaluation_config=dict(explore=False, replay_sequence_length=-1),\n",
    "    evaluation_num_episodes=rollouts,\n",
    ")\n",
    "\n",
    "def generate(savename):\n",
    "    init(**args)\n",
    "    \n",
    "    frames = []\n",
    "    for graph in tqdm(graphs, 'graphs'):\n",
    "        for agent_type in tqdm(agent_types, f' {graph.graph_size}'):\n",
    "            agent_name = agent_type.split(\"/\")[-1]\n",
    "            for seed in tqdm(seeds, f'\\u00a0\\u2001\\u2001\\u2001 {agent_name}@{graph.graph_size}'):\n",
    "                config = dict(\n",
    "                    framework=\"torch\",\n",
    "                    model=dict(use_lstm=True),\n",
    "                    env=AttackSimulationEnv,\n",
    "                    env_config=dict(attack_graph=graph),\n",
    "                    seed=seed,\n",
    "                    num_workers=0,\n",
    "                    log_level='ERROR',\n",
    "                )\n",
    "                if agent_type in DEFENDERS:\n",
    "                    config.update(eval_config)\n",
    "                    agent = template_agent(agent_type)(config=config)\n",
    "                else:\n",
    "                    if agent_type == \"contrib/AlphaZero\":\n",
    "                        config[\"env_config\"].update(env_class=AttackSimAlphaZeroEnv)\n",
    "                        config.update(\n",
    "                            env=AlphaZeroWrapper,\n",
    "                            model=dict(custom_model=\"alpha_zero_dense_model\"),\n",
    "                            rollout_fragment_length=32,\n",
    "                            train_batch_size=1280,\n",
    "                            sgd_minibatch_size=64,\n",
    "                        )\n",
    "\n",
    "                    name = f'{agent_name}_{graph.graph_size}_{seed}'\n",
    "                    if not os.path.exists(name):\n",
    "                        config.update(num_workers=4, batch_mode=\"complete_episodes\")\n",
    "                        with keep_ipython_sane():\n",
    "                            agent = rllib.agents.registry.get_trainer_class(agent_type)(config=config)\n",
    "                        for _ in tqdm(range(iterations), f'\\u00a0\\u2001\\u2001\\u2001\\u2001\\u2001\\u2001 {name}'):\n",
    "                            results = agent.train()\n",
    "                            # TODO: break based on results?\n",
    "                        agent.save(name)\n",
    "                        del agent\n",
    "\n",
    "                    config.update(eval_config, num_workers=0)\n",
    "                    with keep_ipython_sane():\n",
    "                        agent = rllib.agents.registry.get_trainer_class(agent_type)(config=config)\n",
    "                    checkpoint_path = TrainableUtil.get_checkpoints_paths(name).chkpt_path[0]\n",
    "                    agent.restore(checkpoint_path)\n",
    "\n",
    "                stats = agent.evaluate()['evaluation']['hist_stats']\n",
    "                frame = pd.DataFrame(dict(agent_type=agent_type, graph_size=graph.num_attacks, **stats))\n",
    "                frames.append(frame)\n",
    "    shutdown()\n",
    "    results_df = pd.concat(frames, ignore_index=True).rename(columns=rename)\n",
    "    results_df.to_csv(savename)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a1282-533b-4d8a-bb9e-f6c67464b470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savename = \"returns-agent-eval.csv\"\n",
    "\n",
    "df = generate(savename) if not os.path.exists(savename) else pd.read_csv(savename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ae506-5fc6-4fcf-b1fe-91a2df9f12ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c984bbe-82c6-4dca-8436-6d78cf97d68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\", rc={\"figure.figsize\": (12, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5424a47-3486-472b-a604-779d30ca7b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=df, x=\"Graph size\", y=\"Returns\", hue=\"Agent\", ci=\"sd\")\n",
    "g.legend(title=\"Agent\", loc=\"lower left\")\n",
    "g.set_title(\"Returns vs Size (random attacker)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2d787-49db-4d90-a8ae-a69d97c085f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=df, x=\"Graph size\", y=\"Episode lengths\", hue=\"Agent\", ci=\"sd\")\n",
    "g.legend(title=\"Agent\", loc=\"upper left\")\n",
    "g.set_title(\"Episode lengths vs Size (random attacker)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6d9d1-2b14-4e48-a4a9-85785a112121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 32)\n",
    "df.groupby(\"Agent\").describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
